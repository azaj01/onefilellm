#!/usr/bin/env python3
"""
Auto-generated test file for OneFileLLM
Test Name: alias-multi
Generated: 2025-06-12 15:55:29 UTC
Command: python onefilellm.py test-multi

Recorded test for: test-multi

This test was automatically generated by the OneFileLLM test recording system.
"""

import pytest
import sys
import os
from pathlib import Path

# Add the parent directory to the path so we can import the test harness
sys.path.insert(0, str(Path(__file__).parent))

from harness_claude1 import run_program, run_program_expect_success


@pytest.mark.unit
@pytest.mark.alias
class TestRecordedAlias_Multi:
    """Auto-generated test class for recorded command execution."""
    
    def test_alias_multi(self, snapshot):
        """
        Recorded test for: test-multi
        
        This test captures the exact output of running:
        python onefilellm.py test-multi
        """
        # Execute the command that was recorded
        args = ['test-multi']
        
        # Run the program and capture output
        output = run_program(args)
        
        # Assert against the recorded snapshot
        snapshot.assert_match(output, "alias_multi_9642a269")
    
    def test_alias_multi_success_expectation(self):
        """
        Verify that the recorded command executes successfully (exit code 0).
        
        This test ensures the command doesn't fail with errors.
        """
        args = ['test-multi']
        
        # This will raise AssertionError if the command fails
        output = run_program_expect_success(args)
        
        # Basic sanity checks on the output
        assert isinstance(output, str), "Output should be a string"
        assert len(output) > 0, "Output should not be empty"


if __name__ == "__main__":
    # Allow running this test file directly
    pytest.main([__file__, "-v"])
